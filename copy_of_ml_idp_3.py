# -*- coding: utf-8 -*-
"""Copy of ml-idp-3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LOupMWCNDymv0Rm6KUEFyFq_cjNN5dax
"""

from google.colab import drive
drive.mount('/content/drive')

image_folder = "/content/drive/My Drive/test_images"

import os

image_folder = "/content/drive/My Drive/test_images"
print("Files in dataset:", os.listdir(image_folder))

!pip install --quiet catboost

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tensorflow.keras.applications import ResNet50, Xception, MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, accuracy_score
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import VotingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression

# ðŸ”¹ Load & Preprocess Images
def load_and_preprocess_images(image_folder):
    images = []
    filenames = []

    for filename in os.listdir(image_folder):
        img_path = os.path.join(image_folder, filename)
        img = load_img(img_path, target_size=(224, 224))
        img_array = img_to_array(img) / 255.0  # Normalize
        images.append(img_array)
        filenames.append(filename)

    images = np.array(images)

        # Ensure correct shape for CNNs
    if images.shape[-1] == 1:
        images = np.repeat(images, 3, axis=-1)  # Convert grayscale to RGB

    return images, filenames

#  Extract Features using CNNs
def extract_features_cnn(model, images):
    return model.predict(images, verbose=0)

image_folder = "/content/drive/My Drive/test_images"  # Change this!
images, filenames = load_and_preprocess_images(image_folder)

from tensorflow.keras.layers import GlobalAveragePooling2D

#  Load CNN Models (Feature Extraction)
base_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_xception = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

model_resnet = Model(inputs=base_resnet.input, outputs=Model(base_resnet.output, GlobalAveragePooling2D()(base_resnet.output)).output)
model_xception = Model(inputs=base_xception.input, outputs=Model(base_xception.output, GlobalAveragePooling2D()(base_xception.output)).output)
model_mobilenet = Model(inputs=base_mobilenet.input, outputs=Model(base_mobilenet.output, GlobalAveragePooling2D()(base_mobilenet.output)).output)

print("Image shape before feature extraction:", images.shape)

# Ensure correct shape (batch_size, 224, 224, 3)
if len(images.shape) == 3:
    images = np.expand_dims(images, axis=0)  # Add batch dimension
elif images.shape[-1] == 1:
    images = np.repeat(images, 3, axis=-1)  # Convert grayscale to RGB

print("Updated image shape:", images.shape)

def extract_features_cnn(model, images):
    """Extract features from CNN model while ensuring correct shape."""
    images = np.array(images, dtype=np.float32)  # Ensure float32 format
    return model.predict(images, verbose=0)

from sklearn.manifold import TSNE

# Reduce dimensionality to 2D for visualization
tsne = TSNE(n_components=2, random_state=42)
features_2d = tsne.fit_transform(combined_features)

# Plot features
plt.figure(figsize=(10, 6))
plt.scatter(features_2d[:, 0], features_2d[:, 1], c=labels, cmap='viridis', alpha=0.7)
plt.colorbar(label="Cluster Labels")
plt.xlabel("t-SNE Component 1")
plt.ylabel("t-SNE Component 2")
plt.title("Feature Distribution using t-SNE")
plt.show()

from tensorflow.keras.layers import GlobalAveragePooling2D

# Define feature extraction models
base_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_xception = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

model_resnet = Model(inputs=base_resnet.input, outputs=GlobalAveragePooling2D()(base_resnet.output))
model_xception = Model(inputs=base_xception.input, outputs=GlobalAveragePooling2D()(base_xception.output))
model_mobilenet = Model(inputs=base_mobilenet.input, outputs=GlobalAveragePooling2D()(base_mobilenet.output))

features_resnet = extract_features_cnn(model_resnet, images)
features_xception = extract_features_cnn(model_xception, images)
features_mobilenet = extract_features_cnn(model_mobilenet, images)

print("Feature extraction successful!")
print("ResNet Features Shape:", features_resnet.shape)
print("Xception Features Shape:", features_xception.shape)
print("MobileNet Features Shape:", features_mobilenet.shape)

combined_features = np.hstack([features_resnet, features_xception, features_mobilenet])

# ðŸ”¹ Unsupervised Clustering (K-Means)
num_clusters = 2  # Adjust based on dataset
kmeans = KMeans(n_clusters=num_clusters, random_state=42)
kmeans.fit(combined_features)
labels = kmeans.labels_

silhouette_avg = silhouette_score(combined_features, labels)
print("Silhouette Score for Clustering:", silhouette_avg)

from sklearn.manifold import TSNE

# Reduce high-dimensional features to 2D using t-SNE
tsne = TSNE(n_components=2, random_state=42)
features_2d = tsne.fit_transform(combined_features)

print("t-SNE transformation successful! Shape:", features_2d.shape)

import seaborn as sns
import matplotlib.pyplot as plt

# K-Means Clustering Visualization
plt.figure(figsize=(10, 6))
sns.scatterplot(x=features_2d[:, 0], y=features_2d[:, 1], hue=labels, palette="deep", alpha=0.7)
plt.title("K-Means Clustering Results")
plt.xlabel("t-SNE Component 1")
plt.ylabel("t-SNE Component 2")
plt.legend(title="Cluster Labels")
plt.show()

#  Display Sample Images with Clusters
num_samples = 5
plt.figure(figsize=(12, 4))
for i in range(num_samples):
    idx = np.random.randint(0, len(images))
    plt.subplot(1, num_samples, i + 1)
    plt.imshow(images[idx])
    plt.title(f"Cluster: {labels[idx]}")
    plt.axis("off")
plt.show()

import matplotlib.pyplot as plt
import random

# Ensure 'labels' is available
if 'labels' not in globals():
    print("Error: 'labels' is not defined. Run K-Means clustering first.")

# Define number of samples to display
num_samples = min(5, len(images))

# Randomly select sample indices
sample_indices = random.sample(range(len(images)), num_samples)

# Plot the selected images with their cluster labels
plt.figure(figsize=(15, 5))
for i, idx in enumerate(sample_indices):
    plt.subplot(1, num_samples, i + 1)
    plt.imshow(images[idx])  # Assuming images are in (224, 224, 3) format
    plt.title(f"Cluster: {labels[idx]}")  # Ensure 'labels' exists
    plt.axis("off")

plt.show()

true_labels = labels  # If true labels are unknown, use K-Means labels

X_train, X_test, y_train, y_test = train_test_split(combined_features, true_labels, test_size=0.2, random_state=42)

# Apply SMOTE (Handle Class Imbalance)
if len(np.unique(y_train)) > 1:  # Only apply if there are multiple classes
    smote = SMOTE(random_state=42)
    X_train, y_train = smote.fit_resample(X_train, y_train)

#  Train Machine Learning Models
from sklearn.ensemble import AdaBoostClassifier

xgb = XGBClassifier(n_estimators=100, learning_rate=0.05, max_depth=3, random_state=42)
lgbm = LGBMClassifier(n_estimators=100, learning_rate=0.05, max_depth=3, random_state=42)
ada = AdaBoostClassifier(n_estimators=100, learning_rate=0.05, random_state=42)

# Train models
xgb.fit(X_train, y_train)
lgbm.fit(X_train, y_train)
ada.fit(X_train, y_train)

# Predict on Test Data
y_pred_xgb = xgb.predict(X_test)
y_pred_lgbm = lgbm.predict(X_test)
y_pred_ada = ada.predict(X_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Performance Metrics for XGBoost
acc_xgb = accuracy_score(y_test, y_pred_xgb)
prec_xgb = precision_score(y_test, y_pred_xgb, average="weighted")
rec_xgb = recall_score(y_test, y_pred_xgb, average="weighted")
f1_xgb = f1_score(y_test, y_pred_xgb, average="weighted")

# Performance Metrics for LightGBM
acc_lgbm = accuracy_score(y_test, y_pred_lgbm)
prec_lgbm = precision_score(y_test, y_pred_lgbm, average="weighted")
rec_lgbm = recall_score(y_test, y_pred_lgbm, average="weighted")
f1_lgbm = f1_score(y_test, y_pred_lgbm, average="weighted")

# Performance Metrics for AdaBoost
acc_ada = accuracy_score(y_test, y_pred_ada)
prec_ada = precision_score(y_test, y_pred_ada, average="weighted")
rec_ada = recall_score(y_test, y_pred_ada, average="weighted")
f1_ada = f1_score(y_test, y_pred_ada, average="weighted")

# Display Results
print(f" XGBoost Accuracy: {acc_xgb:.4f}, Precision: {prec_xgb:.4f}, Recall: {rec_xgb:.4f}, F1-score: {f1_xgb:.4f}")
print(f" LightGBM Accuracy: {acc_lgbm:.4f}, Precision: {prec_lgbm:.4f}, Recall: {rec_lgbm:.4f}, F1-score: {f1_lgbm:.4f}")
print(f" AdaBoost Accuracy: {acc_ada:.4f}, Precision: {prec_ada:.4f}, Recall: {rec_ada:.4f}, F1-score: {f1_ada:.4f}")

#  Ensemble Model (Voting Classifier)
ensemble_model = VotingClassifier(estimators=[('xgb', xgb), ('lgbm', lgbm), ('ada', ada)], voting='soft')
ensemble_model.fit(X_train, y_train)

y_pred_ensemble = ensemble_model.predict(X_test)
acc_ensemble = accuracy_score(y_test, y_pred_ensemble)
print(f"Voting Ensemble Accuracy: {acc_ensemble:.4f}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred_ensemble)

# Display the confusion matrix
plt.figure(figsize=(6, 5))
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix - Voting Classifier")
plt.show()

#  Stacking Model
meta_model = LogisticRegression()
stacked_model = StackingClassifier(estimators=[('xgb', xgb), ('lgbm', lgbm), ('ada', ada)], final_estimator=meta_model)
stacked_model.fit(X_train, y_train)

y_pred_stacked = stacked_model.predict(X_test)
acc_stacked = accuracy_score(y_test, y_pred_stacked)
print(f"Stacked Model Accuracy: {acc_stacked:.4f}")